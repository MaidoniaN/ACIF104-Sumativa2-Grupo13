# ğŸ’° PredicciÃ³n de Ingresos con Deep Learning (Adult Census) - Sumativa 2

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange)
![Streamlit](https://img.shields.io/badge/Streamlit-App-red)
![Status](https://img.shields.io/badge/Status-Entregado-green)

Este proyecto corresponde a la **EvaluaciÃ³n Sumativa 2** del curso ACIF104. El objetivo es desarrollar y desplegar un modelo de Deep Learning robusto capaz de predecir si un individuo percibe ingresos anuales superiores a $50,000 USD, basÃ¡ndose en datos sociodemogrÃ¡ficos sensibles, con un fuerte enfoque en la **Ã©tica, la explicabilidad (XAI) y el monitoreo**.

## ğŸ“‹ Tabla de Contenidos
- [DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
- [MetodologÃ­a](#-metodologÃ­a)
- [TecnologÃ­as Utilizadas](#-tecnologÃ­as-utilizadas)
- [Resultados Clave](#-resultados-clave)
- [Estructura del Repositorio](#-estructura-del-repositorio)
- [InstalaciÃ³n y ConfiguraciÃ³n](#-instalaciÃ³n-y-configuraciÃ³n)
- [EjecuciÃ³n de la AplicaciÃ³n (API)](#-ejecuciÃ³n-de-la-aplicaciÃ³n-api)
- [EjecuciÃ³n en Google Colab](#-ejecuciÃ³n-en-google-colab)
- [Autores](#-autores)

## ğŸ§ DescripciÃ³n del Proyecto
Utilizando el dataset "Adult Census", este proyecto implementa una metodologÃ­a completa CRISP-DM que incluye:
1.  **AnÃ¡lisis Exploratorio (EDA):** DetecciÃ³n de desbalance severo y sesgos en variables sensibles.
2.  **Modelado:** ComparaciÃ³n de arquitecturas de Deep Learning (MLP vs Wide & Deep). El modelo ganador utiliza **Dropout** para mejorar la generalizaciÃ³n.
3.  **Despliegue:** Una aplicaciÃ³n web interactiva que permite realizar inferencias en tiempo real.
4.  **Ã‰tica y Monitoreo:** Estrategias para mitigar sesgos y vigilar el *data drift* en producciÃ³n.


## ğŸš€ MetodologÃ­a
El proyecto sigue un flujo de trabajo de Ciencia de Datos riguroso:

1.  **EDA y Limpieza:** Manejo de valores nulos (`?`), anÃ¡lisis de outliers y eliminaciÃ³n de redundancias (`education` vs `education-num`).
2.  **Preprocesamiento:** Pipeline con `StandardScaler` para numÃ©ricas y `OneHotEncoder` para categÃ³ricas.
3.  **Machine Learning ClÃ¡sico (Baseline):** Comparativa entre RegresiÃ³n LogÃ­stica, Random Forest y SVM.
4.  **Estrategias de Balanceo:** Pruebas con *Baseline*, *SMOTE* y *Class Weights*.
5.  **Deep Learning:** ImplementaciÃ³n y comparaciÃ³n de tres arquitecturas:
    * MLP BÃ¡sico.
    * MLP con RegularizaciÃ³n (Dropout).
    * Arquitectura Wide & Deep.
6.  **Refinamiento:** Ajuste de hiperparÃ¡metros automatizado usando **KerasTuner**.
7.  **Explicabilidad:** AnÃ¡lisis interpretativo del modelo final utilizando **SHAP** (SHapley Additive exPlanations).

## ğŸ›  TecnologÃ­as Utilizadas
* **Python 3**
* **Pandas & NumPy:** ManipulaciÃ³n de datos.
* **Matplotlib & Seaborn:** VisualizaciÃ³n de datos.
* **Scikit-Learn:** Preprocesamiento y modelos clÃ¡sicos.
* **TensorFlow / Keras:** ConstrucciÃ³n de redes neuronales.
* **Keras Tuner:** OptimizaciÃ³n de hiperparÃ¡metros.
* **Imbalanced-learn:** TÃ©cnica SMOTE.
* **SHAP:** Interpretabilidad del modelo.

## ğŸ† Resultados Clave

Tras experimentar con mÃºltiples arquitecturas, el modelo **MLP con Dropout (30%)** resultÃ³ ser el ganador, superando incluso a modelos optimizados automÃ¡ticamente y arquitecturas hÃ­bridas complejas. Esto demostrÃ³ la importancia de la regularizaciÃ³n simple frente al desbalance de datos.

| Modelo | F1-Score (>50K) | AUC-ROC | ConclusiÃ³n |
| :--- | :---: | :---: | :--- |
| **MLP + Dropout (Ganador)** | **0.6836** | **0.9071** | Mejor equilibrio y generalizaciÃ³n. |
| Wide & Deep | 0.6812 | 0.9058 | Muy competitivo, arquitectura robusta. |
| MLP Optimizado (Tuner) | 0.6804 | 0.9070 | Excelente AUC, pero menor F1. |
| MLP BÃ¡sico | 0.6774 | 0.9024 | Buen baseline, tiende al sobreajuste. |

**Insights de SHAP:**
El anÃ¡lisis de interpretabilidad revelÃ³ que el **Estado Civil** (especÃ­ficamente estar casado), la **Edad**, los **AÃ±os de EducaciÃ³n** y las **Ganancias de Capital** son los predictores mÃ¡s fuertes para tener ingresos altos.


## ğŸ“‚ Estructura del Repositorio

El proyecto estÃ¡ organizado de manera modular para separar el anÃ¡lisis, la documentaciÃ³n y el despliegue:

```text
â”œâ”€â”€ API/                          # MÃ³dulo de la AplicaciÃ³n Web
â”‚   â”œâ”€â”€ adult.csv                 # Dataset fuente
â”‚   â”œâ”€â”€ app.py                    # CÃ³digo principal de la aplicaciÃ³n Streamlit
â”‚   â”œâ”€â”€ backup_app.py             # VersiÃ³n de respaldo de la app
â”‚   â”œâ”€â”€ entrenar_local.py         # Script para regenerar modelos localmente
â”‚   â”œâ”€â”€ modelo_ingresos.keras     # Modelo de Red Neuronal entrenado
â”‚   â”œâ”€â”€ preprocessor.joblib       # Pipeline de preprocesamiento
â”‚   â”œâ”€â”€ shap_background.joblib    # Datos de fondo para explicabilidad SHAP
â”‚   â”œâ”€â”€ columnas_input.joblib     # Metadatos de columnas
â”‚   â”œâ”€â”€ prediction_logs.csv       # Registro (log) de predicciones
â”‚   â”œâ”€â”€ roc_curves_comparison.png # GrÃ¡fico de rendimiento
â”‚   â””â”€â”€ requeriments.txt          # Dependencias especÃ­ficas de la API
â”‚
â”œâ”€â”€ Informe/                      # DocumentaciÃ³n Formal
â”‚   â””â”€â”€ ACIF104_S10_Grupo13.docx  # Informe final detallado
â”‚
â”œâ”€â”€ Images/                      # DocumentaciÃ³n Formal
â”‚   â””â”€â”€ Prediction1.txt          # Informe final detallado
â”‚   â””â”€â”€ Prediction2.txt          # Informe final detallado
â”‚
â”œâ”€â”€ Notebook/                     # AnÃ¡lisis y ExperimentaciÃ³n
â”‚   â””â”€â”€ ACIF104_S10_Grupo13.ipynb # Jupyter Notebook con todo el cÃ³digo del proyecto
â”‚
â”œâ”€â”€ README.md                     # Este archivo
â””â”€â”€ requeriments.txt              # Dependencias generales del proyecto

```

## ğŸ”§ InstalaciÃ³n y ConfiguraciÃ³n

Sigue estos pasos para ejecutar el proyecto en tu entorno local (Linux/Mac/Windows).

### 1. Clonar el Repositorio
```
git clone [https://github.com/MaidoniaN/ACIF104-Sumativa2-Grupo13.git](https://github.com/MaidoniaN/ACIF104-Sumativa2-Grupo13.git)
cd ACIF104-Sumativa2-Grupo13
```

### 2. Configurar Entorno Virtual (Recomendado)
Para evitar conflictos de versiones, crea un entorno aislado:

```
# Crear entorno
python3 -m venv venv

# Activar entorno (Linux/Mac)
source venv/bin/activate

# Activar entorno (Windows)
venv\Scripts\activate
```

### 3. Instalar Dependencias
Instala las librerÃ­as necesarias listadas en el archivo raÃ­z. (Nota: AsegÃºrate de usar el nombre exacto del archivo que tienes en tu carpeta)

```
pip install -r requeriments.txt.
```

## ğŸš€ EjecuciÃ³n de la AplicaciÃ³n (API)
La aplicaciÃ³n web (Frontend + Backend) se encuentra en la carpeta API. Es importante ejecutarla desde allÃ­ para que encuentre los archivos .keras y .csv correctamente.

### Paso 1: Navegar a la carpeta API
```
cd API
```

### Paso 2: (Opcional) Regenerar Artefactos Locales Si tienes problemas de compatibilidad al cargar el modelo (errores de sklearn o versiones), ejecuta este script para re-entrenar y guardar el modelo en tu mÃ¡quina:


```
python3 entrenar_local.py
```

Espera a ver el mensaje: "Â¡LISTO! Archivos generados correctamente."

### Paso 3: Iniciar la App

Ejecutar el siguiente comando en el directorio API

```
streamlit run app.py
```
![Interfaz de la App Streamlit](Images/AppRUN.png)

La aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en tu navegador en http://localhost:8501.
Una vez que inicia con la aplicaciÃ³n, podemos hacer predicciones.
Para ello debemos realizar lo siguiente:
1. Seteamos los parÃ¡metros de la barra de la izquierda de acuerdo con las caracterÃ­sticas de un sujeto de interÃ©s.

- Edad
- Clase de Trabajo
- AÃ±os de educaciÃ³n
- Nacionalidad
- etc

2. Luego presionamos "Calcular". El algoritmo ejecutara el modelo predictivo y nos entregara una respuesta.

Para el caso de la imagen, el sujeto tiene un 85.6% de "Probabilidades" de obtener 50Mil al aÃ±o.

![Interfaz de la App Streamlit](Images/Prediction1.png)

Ahora bien, para una segunda predicciÃ³n, solo se modifico la caracterÃ­stica del PaÃ­s, paso de "Estados Unidos" a "El Salvador" y el resultado de la predicciÃ³n es mas baja, obteniendo solo un 62.7% de "Probabilidades" de ganar mas de 50Mil al aÃ±o.


![Interfaz de la App Streamlit](Images/Prediction2.png)

## â˜ EjecuciÃ³n en Google Colab

Si prefieres revisar el anÃ¡lisis sin instalar nada localmente:

1. Abre el archivo Notebook/ACIF104_S10_Grupo13.ipynb en el repositorio de GitHub.

2. Haz clic en el botÃ³n "Open in Colab" (si estÃ¡ disponible) o descarga el archivo y sÃºbelo a Google Colab.

3. Para cargar el dataset y utilidades, ejecuta en la primera celda del notebook:

```
!git clone [https://github.com/MaidoniaN/ACIF104-Sumativa2-Grupo13.git](https://github.com/MaidoniaN/ACIF104-Sumativa2-Grupo13.git)
%cd ACIF104-Sumativa2-Grupo13/API
!pip install -r requeriments.txt
```

## ğŸ‘¥ Autores
### Grupo 13 - Aprendizaje de MÃ¡quinas (ACIF104)
- Alonso Cid Riveros
- Scarlett Espinoza Contreras
- Christian Mattioni Avila
