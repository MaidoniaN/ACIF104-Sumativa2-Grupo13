# ACIF104-Sumativa1-Grupo1
En este repositorio podran encontrar los elementos utilizados en el desarrollo de la actividad Sumativa 1, del curso Aprendizaje de Maquina APTRC106 de la Universidad Andr茅s Bello.

#  Predicci贸n de Ingresos con Deep Learning (Adult Census Dataset)

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange)
![Status](https://img.shields.io/badge/Status-Completado-green)

Este proyecto aborda la problem谩tica de la clasificaci贸n de ingresos utilizando el famoso conjunto de datos **Adult Census Income**. El objetivo principal es desarrollar un modelo de Aprendizaje Autom谩tico capaz de predecir si una persona gana m谩s de **$50,000 anuales**, bas谩ndose en caracter铆sticas demogr谩ficas y laborales.

Este trabajo corresponde a la **Evaluaci贸n Sumativa (Fase 2)** del curso de Aprendizaje de M谩quinas.

##  Tabla de Contenidos
- [Descripci贸n del Problema](#-descripci贸n-del-problema)
- [Metodolog铆a](#-metodolog铆a)
- [Tecnolog铆as Utilizadas](#-tecnolog铆as-utilizadas)
- [Resultados Clave](#-resultados-clave)
- [Instalaci贸n y Uso](#-instalaci贸n-y-uso)
- [Estructura del Repositorio](#-estructura-del-repositorio)
- [Autores](#-autores)

##  Descripci贸n del Problema
La desigualdad de ingresos y los factores que influyen en ella son temas cr铆ticos. Utilizando datos del censo de 1994, buscamos construir un modelo predictivo robusto que pueda identificar patrones asociados a altos ingresos.

El desaf铆o t茅cnico principal es el **fuerte desbalance de clases** (solo el ~24% de los registros corresponden a ingresos `>50K`), lo que requiere estrategias espec铆ficas de modelado y evaluaci贸n.

##  Metodolog铆a
El proyecto sigue un flujo de trabajo de Ciencia de Datos riguroso:

1.  **EDA y Limpieza:** Manejo de valores nulos (`?`), an谩lisis de outliers y eliminaci贸n de redundancias (`education` vs `education-num`).
2.  **Preprocesamiento:** Pipeline con `StandardScaler` para num茅ricas y `OneHotEncoder` para categ贸ricas.
3.  **Machine Learning Cl谩sico (Baseline):** Comparativa entre Regresi贸n Log铆stica, Random Forest y SVM.
4.  **Estrategias de Balanceo:** Pruebas con *Baseline*, *SMOTE* y *Class Weights*.
5.  **Deep Learning:** Implementaci贸n y comparaci贸n de tres arquitecturas:
    * MLP B谩sico.
    * MLP con Regularizaci贸n (Dropout).
    * Arquitectura Wide & Deep.
6.  **Refinamiento:** Ajuste de hiperpar谩metros automatizado usando **KerasTuner**.
7.  **Explicabilidad:** An谩lisis interpretativo del modelo final utilizando **SHAP** (SHapley Additive exPlanations).

##  Tecnolog铆as Utilizadas
* **Python 3**
* **Pandas & NumPy:** Manipulaci贸n de datos.
* **Matplotlib & Seaborn:** Visualizaci贸n de datos.
* **Scikit-Learn:** Preprocesamiento y modelos cl谩sicos.
* **TensorFlow / Keras:** Construcci贸n de redes neuronales.
* **Keras Tuner:** Optimizaci贸n de hiperpar谩metros.
* **Imbalanced-learn:** T茅cnica SMOTE.
* **SHAP:** Interpretabilidad del modelo.

##  Resultados Clave

Tras experimentar con m煤ltiples arquitecturas, el modelo **MLP con Dropout (30%)** result贸 ser el ganador, superando incluso a modelos optimizados autom谩ticamente y arquitecturas h铆bridas complejas. Esto demostr贸 la importancia de la regularizaci贸n simple frente al desbalance de datos.

| Modelo | F1-Score (>50K) | AUC-ROC | Conclusi贸n |
| :--- | :---: | :---: | :--- |
| **MLP + Dropout (Ganador)** | **0.6836** | **0.9071** | Mejor equilibrio y generalizaci贸n. |
| Wide & Deep | 0.6812 | 0.9058 | Muy competitivo, arquitectura robusta. |
| MLP Optimizado (Tuner) | 0.6804 | 0.9070 | Excelente AUC, pero menor F1. |
| MLP B谩sico | 0.6774 | 0.9024 | Buen baseline, tiende al sobreajuste. |

**Insights de SHAP:**
El an谩lisis de interpretabilidad revel贸 que el **Estado Civil** (espec铆ficamente estar casado), la **Edad**, los **A帽os de Educaci贸n** y las **Ganancias de Capital** son los predictores m谩s fuertes para tener ingresos altos.

##  Instalaci贸n y Uso

### Ejecuci贸n en Google Colab

Si prefieres ejecutar el proyecto en la nube sin instalar nada en tu equipo, sigue estos pasos:

1.  **Abrir el Notebook:**
    Sube el archivo `ACIF104_S6_Grupo13.ipynb` a tu Google Drive y 谩brelo con Google Colab, o 谩brelo directamente desde GitHub.

2.  **Montar el Repositorio y Cargar el Dataset:**
    Para asegurarte de que el notebook tenga acceso al archivo `adult.csv` y a todos los scripts, ejecuta el siguiente comando en la **primera celda** del notebook:

    ```python
    # Clona el repositorio dentro del entorno de Colab
    !git clone [https://github.com/MaidoniaN/ACIF104-Sumativa1-Grupo1.git](https://github.com/MaidoniaN/ACIF104-Sumativa1-Grupo1.git)

    # Cambia el directorio de trabajo a la carpeta del proyecto
    %cd ACIF104-Sumativa1-Grupo1
    ```
    *Esto descargar谩 autom谩ticamente el dataset y los archivos necesarios.*

3.  **Instalar Librer铆as:**
    En una celda siguiente, ejecuta:
    ```python
    !pip install -r requirements.txt
    ```

4.  **Ejecutar Paso a Paso:**
    * Una vez configurado el entorno, ve al men煤 superior **"Entorno de ejecuci贸n"** -> **"Ejecutar todas"** para correr el proyecto completo.
    * Alternativamente, presiona `Shift + Enter` en cada celda para ejecutar el an谩lisis secuencialmente y ver los gr谩ficos interactivos.


##  Estructura del Repositorio

```text
 ACIF104_S6_Grupo13.ipynb         # Notebook principal con todo el c贸digo y an谩lisis
 ACIF104_S6_Grupo13.pdf           # Informe de la actividad
 adult.csv                        # Dataset (si decides subirlo, o instruye descargarlo)
 requirements.txt                 # Lista de librer铆as necesarias
 README.md                        # Este archivo
